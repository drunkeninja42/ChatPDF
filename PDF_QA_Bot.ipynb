{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "1jhImse6c9gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = UnstructuredPDFLoader(\"mining massive datasets.pdf\")"
      ],
      "metadata": {
        "id": "pJLVrSmnczkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ulsg8-deUkR",
        "outputId": "25e076d3-2017-4202-b571-138916c0c72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'You have {len(data)} document(s) in your data')\n",
        "print (f'There are {len(data[0].page_content)} characters in your document')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWsn5Ge-e-O4",
        "outputId": "63fcdae5-139c-445d-c6e9-441f5a24b397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 1 document(s) in your data\n",
            "There are 1198219 characters in your document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "A396ZIhMf93p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'Now you have {len(texts)} documents')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhkX2X1BgITV",
        "outputId": "8ee0e1b8-ac52-4b5c-8a81-dff47521dda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now you have 1239 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma, Pinecone\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2ky127WgLtk",
        "outputId": "260660b0-d978-41d1-b497-878bea70c464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPEN_AI_KEY\"\n",
        "OPENAI_API_KEY = 'open_ai_key'\n",
        "# PINECONE_API_KEY = ''\n",
        "# PINECONE_API_ENV = 'us-east1-gcp'"
      ],
      "metadata": {
        "id": "aSyi95nDgNuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import redis\n",
        "from langchain.vectorstores import ElasticVectorSearch"
      ],
      "metadata": {
        "id": "5k25C32xmf6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "f_KKdxUzmfyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = ElasticVectorSearch.from_documents(texts, embeddings, elasticsearch_url=\"https://elastic:6s68eGqhRYWBFp9hBQBHUiZM@e31b9b04e4184ed38f5d476af442902a.us-central1.gcp.cloud.es.io:9243\")\n",
        "\n",
        "query = \"what are massive datasets\"\n",
        "docs = db.similarity_search(query)"
      ],
      "metadata": {
        "id": "UnO7pZD-0yXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxGdNHwu4jay",
        "outputId": "a9e6a9c5-ab7f-46a7-f060-596c5b59a315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mining\n",
            "\n",
            "of\n",
            "\n",
            "Massive\n",
            "\n",
            "Datasets\n",
            "\n",
            "Jure Leskovec\n",
            "\n",
            "Stanford Univ.\n",
            "\n",
            "Anand Rajaraman\n",
            "\n",
            "Milliway Labs\n",
            "\n",
            "Jeﬀrey D. Ullman\n",
            "\n",
            "Stanford Univ.\n",
            "\n",
            "Copyright c\n",
            "\n",
            "(cid:13)\n",
            "\n",
            "and Jeﬀrey D. Ullman\n",
            "\n",
            "2010, 2011, 2012, 2013, 2014 Anand Rajaraman, Jure Leskovec,\n",
            "\n",
            "ii\n",
            "\n",
            "Preface\n",
            "\n",
            "This book evolved from material developed over several years by Anand Raja-\n",
            "\n",
            "raman and Jeﬀ Ullman for a one-quarter course at Stanford. The course\n",
            "\n",
            "CS345A, titled “Web Mining,” was designed as an advanced graduate course,\n",
            "\n",
            "although it has become accessible and interesting to advanced undergraduates.\n",
            "\n",
            "When Jure Leskovec joined the Stanford faculty, we reorganized the material\n",
            "\n",
            "considerably. He introduced a new course CS224W on network analysis and\n",
            "\n",
            "added material to CS345A, which was renumbered CS246. The three authors\n",
            "\n",
            "also introduced a large-scale data-mining project course, CS341. The book now\n",
            "\n",
            "contains material taught in all three courses.\n",
            "\n",
            "What the Book Is About\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "KlUETx_uDFHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "0UufbriWsnf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = \"what are the methods for high degrees of similarity ?\"\n",
        "docs = db.similarity_search(query1)"
      ],
      "metadata": {
        "id": "iUizshFYsqZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(input_documents=docs, question=query1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E4_NzXlytHw7",
        "outputId": "45a0e8d1-9ecd-4843-e359-b9cc1993e4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Locality-sensitive hashing, shingling, and minhashing.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"who are the autors of the book mining massive datasets ?\"\n",
        "docs = db.similarity_search(query2)"
      ],
      "metadata": {
        "id": "9Aa2xoPAtJY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(input_documents=docs, question=query2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b-AZwQAVtxVq",
        "outputId": "fcbf991b-d1c2-47c3-f9e9-d5ac1ac92fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The authors of the book Mining Massive Datasets are Anand Rajaraman, Jure Leskovec, and Jeffrey D. Ullman.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_kEiY5lRt1x3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}